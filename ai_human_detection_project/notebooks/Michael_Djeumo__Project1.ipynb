{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "m2YBpCtVuQT8",
      "metadata": {
        "id": "m2YBpCtVuQT8"
      },
      "source": [
        "## **1. Importing Necessary Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d72a1911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-02-16T22:12:54.350276Z",
          "iopub.status.busy": "2023-02-16T22:12:54.349329Z",
          "iopub.status.idle": "2023-02-16T22:12:55.394450Z",
          "shell.execute_reply": "2023-02-16T22:12:55.393161Z"
        },
        "id": "d72a1911",
        "outputId": "1818604a-5aa8-4ce0-9240-5f653387bc07",
        "papermill": {
          "duration": 1.064236,
          "end_time": "2023-02-16T22:12:55.397743",
          "exception": false,
          "start_time": "2023-02-16T22:12:54.333507",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " All libraries imported successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping help/tagsets_json.zip.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import joblib\n",
        "import string\n",
        "import math\n",
        "import time\n",
        "\n",
        "# Sklearn libraries for machine learning and text processing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold, cross_validate, validation_curve, learning_curve\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "# NLTK libraries for text processing (lemmatization, stemming, stopwords, POS tagging)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Set up visualization\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "\n",
        "# Download necessary NLTK resources for text processing\n",
        "nltk.download('wordnet')  # WordNet for lemmatization\n",
        "nltk.download('omw-1.4')  # Open Multilingual Wordnet\n",
        "nltk.download('punkt')  # Tokenizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')  # Stopwords for text cleaning\n",
        "nltk.download('averaged_perceptron_tagger')  # POS tagger for part-of-speech tagging\n",
        "nltk.download('averaged_perceptron_tagger_eng')  # Additional tagger\n",
        "nltk.download('tagsets_json')  # Tagset resource\n",
        "\n",
        "print(\"\\n All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jn4E8nvJilw8",
      "metadata": {
        "id": "jn4E8nvJilw8"
      },
      "source": [
        "## **2. Data Overview and Importing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sQaqCgfkmqL8",
      "metadata": {
        "id": "sQaqCgfkmqL8"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "_tpREV5OmU3w",
      "metadata": {
        "id": "_tpREV5OmU3w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ds_train = pd.read_excel('AI_vs_huam_train_dataset.xlsx')\n",
        "ds_test = pd.read_csv('Final_test_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfHiEvFun0cU",
      "metadata": {
        "id": "HfHiEvFun0cU"
      },
      "source": [
        "# ðŸ’¾ Reading a text-based dataset into pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Information:\")\n",
        "print(f\"Training data shape: {ds_train.shape}\")\n",
        "print(f\"Test data shape: {ds_test.shape}\")\n",
        "print(f\"Columns: {ds_train.columns.tolist()}\")\n",
        "\n",
        "# Show first few rows\n",
        "print(\"\\nFirst 5 rows of training data:\")\n",
        "print(ds_train.head())\n",
        "\n",
        "# Check sentiment distribution\n",
        "print(\"\\nSentiment distribution:\")\n",
        "print(ds_train['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzYnhEeurOAp",
        "outputId": "a58b84f5-c7ca-4324-a74e-3a410426c4f4"
      },
      "id": "xzYnhEeurOAp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Information:\n",
            "Training data shape: (3728, 2)\n",
            "Test data shape: (869, 2)\n",
            "Columns: ['essay', 'label']\n",
            "\n",
            "First 5 rows of training data:\n",
            "                                               essay  label\n",
            "0  International sports events require the most w...      0\n",
            "1  Globalisation has become a significant aspect ...      0\n",
            "2  There is an ever-increasing number of bullying...      0\n",
            "3  It is commonly believed, that companies should...      0\n",
            "4  Despite knowing about the adverse effects of c...      0\n",
            "\n",
            "Sentiment distribution:\n",
            "label\n",
            "0    1864\n",
            "1    1864\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xIrMT7wEpFvw",
      "metadata": {
        "id": "xIrMT7wEpFvw"
      },
      "source": [
        "## **3. Text Pre-processing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "memHsjuRpFRD",
      "metadata": {
        "id": "memHsjuRpFRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1796dda1-7179-4e54-f753-439a31f24846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing class created!\n"
          ]
        }
      ],
      "source": [
        "#  Advanced Text Preprocessing with Lemmatization\n",
        "\n",
        "class text_processing:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "    self.STOPWORDS = set(stopwords.words('english'))\n",
        "    self.STOPWORDS.update(['u', 'Ã¼', 'ur', '4', '2', 'im', 'dont', 'doin', 'ure'])\n",
        "\n",
        "\n",
        "\n",
        "  def text_cleaning_and_normalization(self, essay):\n",
        "\n",
        "    # Handle non-string values\n",
        "    if not isinstance(essay, str):\n",
        "        return \"\"\n",
        "    #convert to lowercase\n",
        "    essay = essay.lower()\n",
        "    #remove numerical value and alphanumeric tokens\n",
        "    essay = re.sub(r'\\w*\\d\\w*', '', essay) #using re pattern\n",
        "    #remove punnc\n",
        "    nopunc = ''.join([char for char in essay if char not in string.punctuation])\n",
        "    essay = ' '.join([word for word in nopunc.split() if word.lower() not in self.STOPWORDS])\n",
        "    return essay\n",
        "  #Lemmatization\n",
        "  def lemmatization(self, essay):\n",
        "    tokens = nltk.word_tokenize(essay)\n",
        "    lemmetized_tokens = []\n",
        "    for token in tokens:\n",
        "      if token not in self.STOPWORDS:\n",
        "        lemmetized_tokens.append(self.lemmatizer.lemmatize(token))\n",
        "    return ' '.join(lemmetized_tokens)\n",
        "  #preprocess\n",
        "  def preprocess(self, essay):\n",
        "    cleaned_essay = self.text_cleaning_and_normalization(essay)\n",
        "    lemmatized_text = self.lemmatization(cleaned_essay)\n",
        "    return lemmatized_text\n",
        "\n",
        "print(\"Text preprocessing class created!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Text Preprocessing to the \"text\" column\n",
        "\n",
        "# Initialize the preprocessor\n",
        "preprocessor = text_processing()\n",
        "\n",
        "print(\"Applying advanced text preprocessing with lemmatization...\")\n",
        "\n",
        "# Apply preprocessing to training data\n",
        "ds_train['clean_essay'] = ds_train['essay'].apply(preprocessor.preprocess)\n",
        "\n",
        "# Apply preprocessing to test data\n",
        "ds_test['clean_essay'] = ds_test['essay'].apply(preprocessor.preprocess)\n",
        "\n",
        "print(\"Text preprocessing completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwOIYyXLsSi6",
        "outputId": "5b10d802-0edb-4e65-8002-41b8ad809146"
      },
      "id": "XwOIYyXLsSi6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying advanced text preprocessing with lemmatization...\n",
            "Text preprocessing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show examples of preprocessing\n",
        "ds_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8xDOlBkdsAUs",
        "outputId": "458ab6af-200f-4728-aa60-d5affd231a90"
      },
      "id": "8xDOlBkdsAUs",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               essay  label  \\\n",
              "0  International sports events require the most w...      0   \n",
              "1  Globalisation has become a significant aspect ...      0   \n",
              "2  There is an ever-increasing number of bullying...      0   \n",
              "3  It is commonly believed, that companies should...      0   \n",
              "4  Despite knowing about the adverse effects of c...      0   \n",
              "\n",
              "                                         clean_essay  \n",
              "0  international sport event require welltrained ...  \n",
              "1  globalisation become significant aspect world ...  \n",
              "2  everincreasing number bullying activity numero...  \n",
              "3  commonly believed company dress code policy em...  \n",
              "4  despite knowing adverse effect climate change ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cd8fdfb-7fbb-4ede-ba48-e44f28cc9499\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>International sports events require the most w...</td>\n",
              "      <td>0</td>\n",
              "      <td>international sport event require welltrained ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Globalisation has become a significant aspect ...</td>\n",
              "      <td>0</td>\n",
              "      <td>globalisation become significant aspect world ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There is an ever-increasing number of bullying...</td>\n",
              "      <td>0</td>\n",
              "      <td>everincreasing number bullying activity numero...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>It is commonly believed, that companies should...</td>\n",
              "      <td>0</td>\n",
              "      <td>commonly believed company dress code policy em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Despite knowing about the adverse effects of c...</td>\n",
              "      <td>0</td>\n",
              "      <td>despite knowing adverse effect climate change ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cd8fdfb-7fbb-4ede-ba48-e44f28cc9499')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cd8fdfb-7fbb-4ede-ba48-e44f28cc9499 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cd8fdfb-7fbb-4ede-ba48-e44f28cc9499');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df07e02a-c583-4606-82ad-bcbddf2c8011\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df07e02a-c583-4606-82ad-bcbddf2c8011')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df07e02a-c583-4606-82ad-bcbddf2c8011 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ds_train",
              "summary": "{\n  \"name\": \"ds_train\",\n  \"rows\": 3728,\n  \"fields\": [\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3728,\n        \"samples\": [\n          \"I completely agree with this statement. People achieve success when they try different jobs and excel in them. However, exploring new jobs always comes with risks. Therefore, taking on different and sometimes risky jobs is essential for anyone aiming to succeed.\\n\\nEveryone should try various jobs to discover where their true talents and interests lie. If we keep doing the same thing over and over, we stop growing, lose interest, and eventually become bored. At that point, we have no sense of direction and can\\u201a\\u00c4\\u00f4t move forward.\\n\\nBy trying new things, we are more likely to eventually find our true path and develop ourselves in that area. Many scientists have created the inventions we rely on today by experimenting in different fields. In my view, without experimenting and taking risks, a person cannot reach their full potential. Of course, not experimenting doesn\\u201a\\u00c4\\u00f4t mean someone will fail, but it does limit their possibilities.\\n\\nEnjoying life also means taking on new challenges. In fact, life\\u201a\\u00c4\\u00f4s natural course is to face new tasks each day, and this is key to achieving success.\\n\\nWe see in everyday life that many people in various fields are constantly trying new things. For example, actors take on diverse roles to show their versatility, businesspeople launch new products and marketing strategies, and software engineers develop new programs and technologies.\\n\\nTrying different jobs may lead to failure at times, but that shouldn\\u201a\\u00c4\\u00f4t stop anyone from experimenting. Instead, they should learn from setbacks and keep moving forward, as the saying goes: \\u201a\\u00c4\\u00faFailures are stepping stones to success.\\u201a\\u00c4\\u00f9 Failure teaches us valuable lessons about what works and what doesn\\u201a\\u00c4\\u00f4t, helping us improve over time.\\n\\nIn conclusion, I believe everyone should embrace new challenges and try different tasks\\u201a\\u00c4\\u00eenot just to achieve success, but also to enjoy life from different perspectives.\",\n          \"I believe that people should always try new things and take risks to grow as individuals. If we hold ourselves back when faced with challenges, we\\u201a\\u00c4\\u00f4ll never improve. To be successful, it\\u201a\\u00c4\\u00f4s not enough to stick to what we already know; especially in tough situations, we need to take risks, even if they might lead to mistakes.\\n\\nWithout taking risks, we can\\u201a\\u00c4\\u00f4t achieve significant results in any field. For instance, if I want to become a top manager in the business world, I\\u201a\\u00c4\\u00f4ll have to make many risky decisions. This shows that people with big ambitions shouldn\\u201a\\u00c4\\u00f4t limit themselves to what they\\u201a\\u00c4\\u00f4re already comfortable with\\u201a\\u00c4\\u00eethey should always look for ways to improve.\\n\\nIn conclusion, no one becomes important by playing it safe. To be successful, people need courage and must be willing to make tough choices in order to keep growing.\",\n          \"In my view, there are both pros and cons to trying new things and taking risks. Some people may be hesitant to change the methods of a successful company, while others are more open to it. I used to be someone who avoided taking risks, but my perspective has changed recently. I now believe that achieving success in life often requires stepping out of your comfort zone and embracing new experiences. \\n\\nTake a football player, for example. If he always plays it safe and only reacts without making mistakes, he won\\u201a\\u00c4\\u00f4t improve or reach a professional level. To truly grow, a player must be willing to take risks\\u201a\\u00c4\\u00eelike leaving a team he\\u201a\\u00c4\\u00f4s been with for five years to join a better, more successful team, even if he doesn\\u201a\\u00c4\\u00f4t know the new teammates, coach, or environment.\\n\\nOf course, taking risks and trying new things can also have downsides. There is always a chance things won\\u201a\\u00c4\\u00f4t work out and you might lose something. However, if you never make mistakes, you won\\u201a\\u00c4\\u00f4t learn from your choices or experiences.\\n\\nOn the other hand, there are fields where risk-taking is not advisable, such as Formula One racing. Drivers in this sport cannot afford to take unnecessary risks because even a small mistake can be fatal. For them, success means driving fast but, above all, driving safely.\\n\\nIn conclusion, regarding the statement \\\"Successful people try new things and take risks rather than only doing what they already know how to do well,\\\" I think that being successful often involves taking risks. However, there are situations and professions where it\\u201a\\u00c4\\u00f4s best to stick to what you\\u201a\\u00c4\\u00f4ve learned and mastered.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3728,\n        \"samples\": [\n          \"completely agree statement people achieve success try different job excel however exploring new job always come risk therefore taking different sometimes risky job essential anyone aiming succeed everyone try various job discover true talent interest lie keep thing stop growing lose interest eventually become bored point sense direction can\\u201a\\u00e4\\u00f4t move forward trying new thing likely eventually find true path develop area many scientist created invention rely today experimenting different field view without experimenting taking risk person reach full potential course experimenting doesn\\u201a\\u00e4\\u00f4t mean someone fail limit possibility enjoying life also mean taking new challenge fact life\\u201a\\u00e4\\u00f4s natural course face new task day key achieving success see everyday life many people various field constantly trying new thing example actor take diverse role show versatility businesspeople launch new product marketing strategy software engineer develop new program technology trying different job may lead failure time shouldn\\u201a\\u00e4\\u00f4t stop anyone experimenting instead learn setback keep moving forward saying go \\u201a\\u00e4\\u00fafailures stepping stone success\\u201a\\u00e4\\u00f9 failure teach u valuable lesson work doesn\\u201a\\u00e4\\u00f4t helping u improve time conclusion believe everyone embrace new challenge try different tasks\\u201a\\u00e4\\u00eenot achieve success also enjoy life different perspective\",\n          \"believe people always try new thing take risk grow individual hold back faced challenge we\\u201a\\u00e4\\u00f4ll never improve successful it\\u201a\\u00e4\\u00f4s enough stick already know especially tough situation need take risk even might lead mistake without taking risk can\\u201a\\u00e4\\u00f4t achieve significant result field instance want become top manager business world i\\u201a\\u00e4\\u00f4ll make many risky decision show people big ambition shouldn\\u201a\\u00e4\\u00f4t limit they\\u201a\\u00e4\\u00f4re already comfortable with\\u201a\\u00e4\\u00eethey always look way improve conclusion one becomes important playing safe successful people need courage must willing make tough choice order keep growing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = ds_train['clean_essay']\n",
        "y = ds_train['label']\n",
        "\n",
        "print(f\"Features (X): {len(X)} input text samples\")\n",
        "print(f\"Target (y): {len(y)} labels\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH3u9B6TuGPh",
        "outputId": "f7de6525-4ff7-4179-9116-669053c32652"
      },
      "id": "HH3u9B6TuGPh",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X): 3728 input text samples\n",
            "Target (y): 3728 labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data for Training and Validation Sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)    # stratify=y Maintain label distribution"
      ],
      "metadata": {
        "id": "zwqaEDzevMDb"
      },
      "id": "zwqaEDzevMDb",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data split completed:\")\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Training label distribution: {np.bincount(y_train)}\")\n",
        "print(f\"Validation label distribution: {np.bincount(y_val)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xoTckFBvAgN",
        "outputId": "9c5e6ef1-a1de-4288-f122-fef0212893ca"
      },
      "id": "4xoTckFBvAgN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split completed:\n",
            "Training samples: 2982\n",
            "Validation samples: 746\n",
            "Training label distribution: [1491 1491]\n",
            "Validation label distribution: [373 373]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Representing Text as Numerical Data using TF-IDF vectorization**\n",
        "\n"
      ],
      "metadata": {
        "id": "-jRZsE6uvRBU"
      },
      "id": "-jRZsE6uvRBU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Text to Numbers Using TF-IDF\n",
        "# Create TF-IDF vectorizer with optimal parameters found through experimentation\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=3728,        #limit vocab size to 3728\n",
        "    binary=True,\n",
        "    token_pattern=r'\\b\\w+\\b', #pattern (includes words with 1 char + more)\n",
        "    ngram_range=(1, 1), #minimum 1 max words 1\n",
        "    max_df=0.9,         #Ignore terms appearing in more than 90% of documents\n",
        "    min_df=2            #Ignore terms appearing in less than 2 documents\n",
        ")\n",
        "\n",
        "print(\"TF-IDF Vectorizer created with optimal parameters:\")\n",
        "print(f\"- Max features: 3728\")\n",
        "print(f\"- N-gram range: (1, 1) - unigrams only\")\n",
        "print(f\"- Min document frequency: 2\")\n",
        "print(f\"- Max document frequency: 0.95\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_N92VzkvcXH",
        "outputId": "a338bf83-dfd6-4ddc-af18-6365088f4c9e"
      },
      "id": "2_N92VzkvcXH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Vectorizer created with optimal parameters:\n",
            "- Max features: 3728\n",
            "- N-gram range: (1, 1) - unigrams only\n",
            "- Min document frequency: 2\n",
            "- Max document frequency: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit TF-IDF on training data and transform both sets\n",
        "print(\"Converting text to numerical features using TF-IDF...\")\n",
        "\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
        "\n",
        "print(\"TF-IDF transformation completed!\")\n",
        "print(f\"Training matrix shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Validation matrix shape: {X_val_tfidf.shape}\")\n",
        "\n",
        "# Show some feature names\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "print(f\"Total features created: {len(feature_names)}\")\n",
        "print(f\"Sample features: {list(feature_names[:15])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q11IF29LvqRA",
        "outputId": "acf2e1fe-1a31-4339-bf0d-51d1551d8c72"
      },
      "id": "Q11IF29LvqRA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text to numerical features using TF-IDF...\n",
            "TF-IDF transformation completed!\n",
            "Training matrix shape: (2982, 3728)\n",
            "Validation matrix shape: (746, 3728)\n",
            "Total features created: 3728\n",
            "Sample features: ['abandon', 'ability', 'able', 'abroad', 'absence', 'absolute', 'absolutely', 'absorb', 'abundance', 'abuse', 'academic', 'academically', 'accept', 'acceptable', 'accepted']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Machine Learning Model Training\n"
      ],
      "metadata": {
        "id": "5WLKuIcWyfPb"
      },
      "id": "5WLKuIcWyfPb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Support Vector Machines (SVM)\n",
        "\n",
        "print(\"Training Support Vector Machines (SVM)...\")\n",
        "\n",
        "# Create and train SVM with best parameters\n",
        "svm_model = SVC(\n",
        "    C=100,\n",
        "    kernel='linear',\n",
        "    gamma=0.1,\n",
        "    random_state=42,\n",
        "    probability=True\n",
        ")\n",
        "\n",
        "# lr_model = LogisticRegression(\n",
        "#     C=1.0,                    # Regularization strength (found to be optimal)\n",
        "#     solver='liblinear',       # Optimization algorithm\n",
        "#     random_state=42,          # For reproducible results\n",
        "#     max_iter=1000            # Maximum iterations\n",
        "# )\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "svm_train_time = time.time() - start_time\n",
        "\n",
        "# Make predictions on validation set\n",
        "svm_predictions = svm_model.predict(X_val_tfidf)\n",
        "svm_accuracy = metrics.accuracy_score(y_val, svm_predictions)\n",
        "\n",
        "print(\"Support Vector Machine (SVM) Results:\")\n",
        "print(f\"Training time: {svm_train_time:.3f} seconds\")\n",
        "print(f\"Validation accuracy: {svm_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FySrveKv_5d",
        "outputId": "fd12777c-7721-417b-c3d7-3ffadc32ab78"
      },
      "id": "8FySrveKv_5d",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Support Vector Machines (SVM)...\n",
            "Support Vector Machine (SVM) Results:\n",
            "Training time: 20.545 seconds\n",
            "Validation accuracy: 0.9799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoostClassifier"
      ],
      "metadata": {
        "id": "1m4ubgE7QD0_"
      },
      "id": "1m4ubgE7QD0_"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "#Train AdaBoostClassifier\n",
        "\n",
        "print(\"Training AdaBoostClassifier...\")\n",
        "\n",
        "# Create and train AdaBoostClassifier with best parameters\n",
        "ada_model = AdaBoostClassifier(\n",
        "    n_estimators=50,\n",
        "    learning_rate=1.0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "#Train the model\n",
        "start_time = time.time()\n",
        "ada_model.fit(X_train_tfidf, y_train)\n",
        "ada_train_time = time.time() - start_time\n",
        "\n",
        "#Make predictions on validation set\n",
        "ada_predictions = ada_model.predict(X_val_tfidf)\n",
        "ada_accuracy = metrics.accuracy_score(y_val, ada_predictions)\n",
        "\n",
        "\n",
        "print(\"AdaBoostClassifier Results:\")\n",
        "print(f\"Training time: {ada_train_time:.3f} seconds\")\n",
        "print(f\"Validation accuracy: {ada_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67X3p4x2QLcm",
        "outputId": "efdc4a66-ecb3-44c9-9f52-d16873ce7ce5"
      },
      "id": "67X3p4x2QLcm",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AdaBoostClassifier...\n",
            "AdaBoostClassifier Results:\n",
            "Training time: 2.760 seconds\n",
            "Validation accuracy: 0.9397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Decision Tree\n",
        "\n",
        "print(\"Training Decision Tree model...\")\n",
        "\n",
        "# Create and Decision Tree with best parameters\n",
        "tree_model = DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=None,\n",
        "    random_state=42\n",
        ")\n",
        "# nb_model = MultinomialNB(\n",
        "#     alpha=1.0,               # Smoothing parameter (found to be optimal)\n",
        "#     fit_prior=True           # Learn class prior probabilities\n",
        "# )\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "tree_model.fit(X_train_tfidf, y_train)\n",
        "tree_train_time = time.time() - start_time\n",
        "\n",
        "# Make predictions on validation set\n",
        "tree_predictions = tree_model.predict(X_val_tfidf)\n",
        "tree_accuracy = metrics.accuracy_score(y_val, tree_predictions)\n",
        "\n",
        "print(\"Decision Tree Results:\")\n",
        "print(f\"Training time: {tree_train_time:.3f} seconds\")\n",
        "print(f\"Validation accuracy: {tree_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t89IFL6PwO9i",
        "outputId": "8729ed74-9592-40ee-fb2a-aca5b1f78428"
      },
      "id": "t89IFL6PwO9i",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Decision Tree model...\n",
            "Decision Tree Results:\n",
            "Training time: 0.583 seconds\n",
            "Validation accuracy: 0.9169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Model Performance"
      ],
      "metadata": {
        "id": "vvyLxSh-3PPq"
      },
      "id": "vvyLxSh-3PPq"
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare Model Performance\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Support Vector Machine (SVM):      {svm_accuracy:.4f}\")\n",
        "print(f\"Decision Tree:  {tree_accuracy:.4f}\")\n",
        "print(f\"AdaBoostClassifier: {ada_accuracy:.4f}\")\n",
        "\n",
        "# Determine the best model based on accuracy\n",
        "accuracies = {\n",
        "    \"SVM\": svm_accuracy,\n",
        "    \"AdaBoostClassifier\": ada_accuracy,\n",
        "    \"Decision Tree\": tree_accuracy\n",
        "}\n",
        "\n",
        "# Find the model with the highest accuracy\n",
        "best_model_name = max(accuracies, key=accuracies.get)\n",
        "best_accuracy = accuracies[best_model_name]\n",
        "\n",
        "# Map model names to actual model objects\n",
        "model_map = {\n",
        "    \"SVM\": svm_model,\n",
        "    \"AdaBoostClassifier\": ada_model,\n",
        "    \"Decision Tree\": tree_model\n",
        "}\n",
        "best_model = model_map[best_model_name]\n",
        "\n",
        "# Output\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV0y3uDMwWEW",
        "outputId": "87d2f7eb-471b-4f8a-b6b3-6175fa0c494e"
      },
      "id": "DV0y3uDMwWEW",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Comparison:\n",
            "========================================\n",
            "Support Vector Machine (SVM):      0.9799\n",
            "Decision Tree:  0.9169\n",
            "AdaBoostClassifier: 0.9397\n",
            "\n",
            "Best Model: SVM\n",
            "Best Accuracy: 0.9799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Best Model with Cross-Validation"
      ],
      "metadata": {
        "id": "x9_Ywlbu3WNO"
      },
      "id": "x9_Ywlbu3WNO"
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Best Model with Cross-Validation\n",
        "\n",
        "print(f\"Performing 5-fold cross-validation on {best_model_name}...\")\n",
        "\n",
        "# Perform cross-validation to get more reliable performance estimate\n",
        "cv_scores = cross_val_score(\n",
        "    best_model,\n",
        "    X_train_tfidf,\n",
        "    y_train,\n",
        "    cv=5,              # 5-fold cross-validation\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "print(\"Cross-Validation Results:\")\n",
        "print(f\"CV Scores: {cv_scores}\")\n",
        "print(f\"Mean CV Score: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "print(f\"95% Confidence Interval: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6viTdbVwcJM",
        "outputId": "43140d9c-21ae-4b94-bb44-4e437c618324"
      },
      "id": "K6viTdbVwcJM",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold cross-validation on SVM...\n",
            "Cross-Validation Results:\n",
            "CV Scores: [0.98659966 0.98492462 0.98489933 0.98154362 0.97315436]\n",
            "Mean CV Score: 0.9822\n",
            "Standard Deviation: 0.0048\n",
            "95% Confidence Interval: 0.9822 (+/- 0.0096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Feature Importance (for SVM)"
      ],
      "metadata": {
        "id": "eTYs7JO43nrz"
      },
      "id": "eTYs7JO43nrz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze Feature Importance (for SVM)\n",
        "\n",
        "if best_model_name == \"SVM\":\n",
        "    print(\"Analyzing feature importance for SVM...\")\n",
        "\n",
        "    # Get feature coefficients\n",
        "    feature_coefficients = best_model.coef_.toarray().flatten() #converting the matrix to a dense format NumPy array before calling .argsort()\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Find most important AI features (indicate positive sentiment)\n",
        "    top_AI_indices = feature_coefficients.argsort()[-10:][::-1]\n",
        "    print(\"Top 10 features for AI:\")\n",
        "    for i, idx in enumerate(top_AI_indices, 1):\n",
        "        print(f\"  {i:2d}. {feature_names[idx]:<15} (coefficient: {feature_coefficients[idx]:+.4f})\")\n",
        "\n",
        "    # Find most important negative features (indicate negative sentiment)\n",
        "    top_Human_indices = feature_coefficients.argsort()[:10]\n",
        "    print(\"\\nTop 10 features for Human:\")\n",
        "    for i, idx in enumerate(top_Human_indices, 1):\n",
        "        print(f\"  {i:2d}. {feature_names[idx]:<15} (coefficient: {feature_coefficients[idx]:+.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bHPd79Cwhd7",
        "outputId": "ef6341fa-4e70-4912-c686-873483d100f2"
      },
      "id": "8bHPd79Cwhd7",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing feature importance for SVM...\n",
            "Top 10 features for AI:\n",
            "   1. Ã¤Ã´s             (coefficient: +4.0939)\n",
            "   2. additionally    (coefficient: +3.1959)\n",
            "   3. often           (coefficient: +3.1352)\n",
            "   4. Ã¤Ã´t             (coefficient: +2.9403)\n",
            "   5. it              (coefficient: +2.8576)\n",
            "   6. believe         (coefficient: +2.5727)\n",
            "   7. truly           (coefficient: +2.3580)\n",
            "   8. summary         (coefficient: +2.1881)\n",
            "   9. sticking        (coefficient: +2.0883)\n",
            "  10. willing         (coefficient: +2.0531)\n",
            "\n",
            "Top 10 features for Human:\n",
            "   1. order           (coefficient: -2.4630)\n",
            "   2. conclude        (coefficient: -2.0516)\n",
            "   3. thus            (coefficient: -1.8747)\n",
            "   4. nowadays        (coefficient: -1.8571)\n",
            "   5. addition        (coefficient: -1.7752)\n",
            "   6. argued          (coefficient: -1.7173)\n",
            "   7. get             (coefficient: -1.5407)\n",
            "   8. therefore       (coefficient: -1.4721)\n",
            "   9. hence           (coefficient: -1.4654)\n",
            "  10. indeed          (coefficient: -1.3491)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Model saving for Streamlit deployment**"
      ],
      "metadata": {
        "id": "m7yI4WV5wrt8"
      },
      "id": "m7yI4WV5wrt8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. For Support Vector Machine"
      ],
      "metadata": {
        "id": "eMPsrHuu3xZx"
      },
      "id": "eMPsrHuu3xZx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ML Pipeline for Deployment\n",
        "\n",
        "print(\"Creating ML Pipeline for deployment...\")\n",
        "\n",
        "# Create a complete pipeline that includes preprocessing and prediction\n",
        "if best_model_name == \"SVM\":\n",
        "    final_pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(\n",
        "            max_features=3728,\n",
        "            binary=True,\n",
        "            token_pattern=r'\\b\\w+\\b',\n",
        "            ngram_range=(1, 1),\n",
        "            max_df=0.9,\n",
        "            min_df=2\n",
        "        )),\n",
        "        ('classifier', svm.SVC(C=100, kernel='rbf', gamma=0.1, probability=True\n",
        "        ))\n",
        "    ])\n",
        "elif best_model_name == \"AdaBoostClassifier\":\n",
        "    final_pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(\n",
        "            max_features=3728,\n",
        "            binary=True,\n",
        "            token_pattern=r'\\b\\w+\\b',\n",
        "            ngram_range=(1,1),\n",
        "            max_df=0.9,\n",
        "            min_df=2\n",
        "        )),\n",
        "        ('classifier', AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42))\n",
        "    ])\n",
        "else:\n",
        "    final_pipeline = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(\n",
        "            max_features=3728,\n",
        "            binary=True,\n",
        "            token_pattern=r'\\b\\w+\\b',\n",
        "            ngram_range=(1, 1),\n",
        "            min_df=0.9,\n",
        "            max_df=2,\n",
        "            stop_words='english'\n",
        "        )),\n",
        "        ('classifier', DecisionTreeClassifier(max_features=2000, binary=True, ngram_range=(1,2))), ('classifier', DecisionTreeClassifier(criterion='entropy', max_depth=None))\n",
        "    ])\n",
        "\n",
        "print(\"Pipeline created with steps:\")\n",
        "for name, step in final_pipeline.steps:\n",
        "    print(f\"  {name}: {step.__class__.__name__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i68ASELJw1Xr",
        "outputId": "a933a65f-39d8-49a5-a66d-b1bc310b065a"
      },
      "id": "i68ASELJw1Xr",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating ML Pipeline for deployment...\n",
            "Pipeline created with steps:\n",
            "  tfidf: TfidfVectorizer\n",
            "  classifier: SVC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Final Pipeline on All Training Data\n",
        "\n",
        "print(\"Training final pipeline on all available training data...\")\n",
        "\n",
        "# Train pipeline on the complete training set\n",
        "final_pipeline.fit(X, y)\n",
        "\n",
        "# Test pipeline performance on validation set\n",
        "pipeline_predictions = final_pipeline.predict(X_val)\n",
        "pipeline_accuracy = metrics.accuracy_score(y_val, pipeline_predictions)\n",
        "\n",
        "print(\"Final Pipeline Results:\")\n",
        "print(f\"Validation accuracy: {pipeline_accuracy:.4f}\")\n",
        "\n",
        "# Show detailed classification report\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "target_names = ['Human', 'AI']\n",
        "classification_report = metrics.classification_report(y_val, pipeline_predictions, target_names=target_names)\n",
        "print(classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD_uJQvrw7UF",
        "outputId": "62a0b570-6c21-4117-d3a4-bdf9c619aecb"
      },
      "id": "DD_uJQvrw7UF",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training final pipeline on all available training data...\n",
            "Final Pipeline Results:\n",
            "Validation accuracy: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       1.00      1.00      1.00       373\n",
            "          AI       1.00      1.00      1.00       373\n",
            "\n",
            "    accuracy                           1.00       746\n",
            "   macro avg       1.00      1.00      1.00       746\n",
            "weighted avg       1.00      1.00      1.00       746\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Models for Streamlit Deployment\n",
        "\n",
        "print(\"Saving models for Streamlit deployment...\")\n",
        "\n",
        "# Save the complete pipeline (includes TF-IDF + classifier)\n",
        "pipeline_filename = 'AI_vs_Human_Analyzer_pipeline.pkl'\n",
        "joblib.dump(final_pipeline, pipeline_filename)\n",
        "\n",
        "# Also save individual components for flexibility\n",
        "tfidf_filename = 'tfidf_vectorizer.pkl'\n",
        "model_filename = f'{best_model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
        "\n",
        "joblib.dump(tfidf_vectorizer, tfidf_filename)\n",
        "joblib.dump(best_model, model_filename)\n",
        "\n",
        "print(\"Models saved successfully!\")\n",
        "print(f\"Complete pipeline: {pipeline_filename}\")\n",
        "print(f\"TF-IDF vectorizer: {tfidf_filename}\")\n",
        "print(f\"Best model: {model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMnNQ9M3xG4G",
        "outputId": "9e1c8b0e-2974-4ac5-a62b-f3356842dbc8"
      },
      "id": "vMnNQ9M3xG4G",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving models for Streamlit deployment...\n",
            "Models saved successfully!\n",
            "Complete pipeline: AI_vs_Human_Analyzer_pipeline.pkl\n",
            "TF-IDF vectorizer: tfidf_vectorizer.pkl\n",
            "Best model: svm_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For AdaBoost"
      ],
      "metadata": {
        "id": "fvI4rRkNVGuM"
      },
      "id": "fvI4rRkNVGuM"
    },
    {
      "cell_type": "code",
      "source": [
        "#Create and train the AdaBoost classifier\n",
        "print(\"Creating AdaBoost classifier...\")\n",
        "ada_classifier = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
        "\n",
        "print(\"Training AdaBoost on existing TF-IDF features...\")\n",
        "ada_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "#Test clasifier performance\n",
        "ada_predictions = ada_classifier.predict(X_val_tfidf)\n",
        "ada_accuracy = metrics.accuracy_score(y_val, ada_predictions)\n",
        "\n",
        "print(f\"\\nAdaBoost Classifier Results:\")\n",
        "print(f\"Validation accuracy: {ada_accuracy:.4f}\")\n",
        "\n",
        "#Show detailed classification report\n",
        "print(\"\\nDetailed Classification Report - AdaBoost:\")\n",
        "target_names = ['Human', 'AI']\n",
        "ada_classification_report = metrics.classification_report(y_val, ada_predictions, target_names=target_names)\n",
        "print(ada_classification_report)\n",
        "\n",
        "#Save The AdaBoost Classifier\n",
        "print(\"Saving AdaBoost Classifier\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "#Save the AdaBoost trained classifier\n",
        "ada_model_filename = 'ada_model.pkl'\n",
        "print(\"Saving AdaBoost classifier...\")\n",
        "joblib.dump(ada_classifier, ada_model_filename)\n",
        "\n",
        "print(f\"\\nAdaBoost classifier saved as: {ada_model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkUycce6VM5t",
        "outputId": "9995028b-b5e1-4f07-c71e-c60452d22fa9"
      },
      "id": "AkUycce6VM5t",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating AdaBoost classifier...\n",
            "Training AdaBoost on existing TF-IDF features...\n",
            "\n",
            "AdaBoost Classifier Results:\n",
            "Validation accuracy: 0.9397\n",
            "\n",
            "Detailed Classification Report - AdaBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.92      0.96      0.94       373\n",
            "          AI       0.96      0.92      0.94       373\n",
            "\n",
            "    accuracy                           0.94       746\n",
            "   macro avg       0.94      0.94      0.94       746\n",
            "weighted avg       0.94      0.94      0.94       746\n",
            "\n",
            "Saving AdaBoost Classifier\n",
            "============================================================\n",
            "Saving AdaBoost classifier...\n",
            "\n",
            "AdaBoost classifier saved as: ada_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. For Decision Tree classifier**"
      ],
      "metadata": {
        "id": "jcz3mafTQ4tt"
      },
      "id": "jcz3mafTQ4tt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the Decision Tree classifier\n",
        "print(\"Creating Decision Tree classifier...\")\n",
        "tree_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=None)\n",
        "\n",
        "print(\"Training Decision Tree on existing TF-IDF features...\")\n",
        "tree_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Test classifier performance\n",
        "tree_predictions = tree_classifier.predict(X_val_tfidf)\n",
        "tree_accuracy = metrics.accuracy_score(y_val, tree_predictions)\n",
        "\n",
        "print(f\"\\nDecision Tree Results:\")\n",
        "print(f\"Validation accuracy: {tree_accuracy:.4f}\")\n",
        "\n",
        "# Show detailed classification report\n",
        "print(\"\\nDetailed Classification Report - Decision Tree:\")\n",
        "target_names = ['Human', 'AI']\n",
        "tree_classification_report = metrics.classification_report(y_val, tree_predictions, target_names=target_names)\n",
        "print(tree_classification_report)\n",
        "\n",
        "# Save The Decision Tree Classifier\n",
        "print(\"Saving Decision Tree Classifier\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save the Decision Tree trained classifier\n",
        "tree_model_filename = 'tree_model.pkl'\n",
        "print(\"Saving Decision Tree classifier...\")\n",
        "joblib.dump(tree_classifier, tree_model_filename)\n",
        "\n",
        "print(f\"\\nDecision Tree classifier saved as: {tree_model_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAFe5rRJTF3V",
        "outputId": "8e109d74-8f8e-4795-a45a-b10c4d9e12e1"
      },
      "id": "OAFe5rRJTF3V",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Decision Tree classifier...\n",
            "Training Decision Tree on existing TF-IDF features...\n",
            "\n",
            "Decision Tree Results:\n",
            "Validation accuracy: 0.9169\n",
            "\n",
            "Detailed Classification Report - Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.92      0.91      0.92       373\n",
            "          AI       0.91      0.92      0.92       373\n",
            "\n",
            "    accuracy                           0.92       746\n",
            "   macro avg       0.92      0.92      0.92       746\n",
            "weighted avg       0.92      0.92      0.92       746\n",
            "\n",
            "Saving Decision Tree Classifier\n",
            "============================================================\n",
            "Saving Decision Tree classifier...\n",
            "\n",
            "Decision Tree classifier saved as: tree_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance evaluation and comparisonsections that include accuracy metrics, confusion matrices, ROC curves, anddetailed analysis comparing the strengths and weaknesses of each model on your specific dataset.\n"
      ],
      "metadata": {
        "id": "BLejO7T76YJr"
      },
      "id": "BLejO7T76YJr",
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 18.393171,
      "end_time": "2023-02-16T22:13:02.202180",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-02-16T22:12:43.809009",
      "version": "2.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}